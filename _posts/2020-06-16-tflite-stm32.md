---  
layout: post  
title: How to run Neural Network model on STM32  
subtitle: Part 1 - Introduction
image: /img/tflite/cover1.png
tags: [stm32, tensorflow, c, c++, python, neural netwrok, machine learning, microcontroller]  
comments: true  
---  
  
# What is TinyML?  
Machine Learning has been changing the world as we know it. With an abundance of data enabled by IoT devices, machine learning found its way even in niche applications. But running a machine learning algorithm requires a beefy workstation. There are machine learning frameworks that can be run on Single Board Computers (e.g. Raspberry Pi) but running on a microcontroller _**was**_ out of the question, until recently.  
  
Tiny Machine Learning or [TinyML](https://www.tinyml.org/) is an emerging area of Machine Learning, where it tries to run various ML models on microcontrollers. [Pete Warden](https://twitter.com/petewarden), one of the key contributors to TinyML, was motivated to start this when he saw the OK Google team uses a 14KB Neural Network model on a DSP Microcontroller to listen for wake words "OK Google". In the 32bit microcontroller market, 14KB is pretty insignificant.  
  
[TensorFlow](https://www.tensorflow.org/) is an end-to-end open-source machine learning platform. There is a TF version specifically for Mobiles and Edge Devices, [TensorFlow Lite](https://www.tensorflow.org/lite), and an experimental port of this framework for microcontrollers, [TensorFlow Lite for Microcontrollers](https://www.tensorflow.org/lite/microcontrollers). From their site:  
>It doesn't require operating system support, any standard C or C++ libraries, or dynamic memory allocation. The core runtime fits in 16 KB on an Arm Cortex M3, and with enough operators to run a speech keyword detection model, takes up a total of 22 KB.  
  
I will show an example of how to run a TFLite model in STM32F746G. I will be using the [**32F746GDISCOVERY**](https://www.st.com/en/evaluation-tools/32f746gdiscovery.html) development board that has an LCD screen and you can buy a camera module as an addon. The example is based on the example that is available on the [TF GitHub](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world).  
  
{: .box-note}  
**Note:** If the STM32 application becomes too much for you I would suggest you try one of their Arduino examples. Those are straight forward examples. I tried the SparkFun Edge example too. Not worth the hassle at the time of writing.  
  
# Why Rewrite the Example  
Here is an excerpt from the TF GitHub:  
>The default reference implementations in TensorFlow Lite Micro are written to be portable and easy to understand. The advantage of this approach is that we can automatically pick specialized implementations based on the microcontroller, without having to manually edit build files. It allows incremental optimization from an always-working foundation, without cluttering the reference implementations with a lot of variants.  
  
>Using macros are hard to extend to multiple platforms. Using macros means that platform-specific code is scattered throughout files in a hard-to-find way and can make following the control flow difficult since you need to understand the macro state to trace it.  
  
I get it. The team wants to support as many microcontrollers as they can. Any Embedded Engineers know, sometimes even two different series of microcontrollers from the same vendor are not the same, not to mention, all the other vendors out there with their variants. That is why all the examples of the TFLite Micro are decoupled and abstracted so that you can easily port from one to another.  
  
* This is the first reason I wanted to rewrite the example. I am mostly interested in STM32 microcontrollers. I am heavily invested into their [ecosystem](https://www.st.com/en/ecosystems/stm32cube.html). From IDE, Monitoring tool, CubeMx to their HAL libraries. I wanted to get away from all those abstractions and keep the example simple so that it is easier to follow.  
  
The GitHub STM32 example uses [Mbed](https://os.mbed.com/). The compilation requires you to install Mbed CLI and Python 2.7. Also, if you are using Windows machine, good luck compiling it because Make fails because of the "path length" being too long.  
  
* These are the other reasons:  
	* As I was already familiar with the STM32 ecosystem, I didn't want to get familiar with the Mbed ecosystem.  
	* The last time I used Python 2.x was back in 2016. I didn't want to mess up my near-perfect environment by installing another Python version.  
	* And, I am a Windows fan. At my current workplace, I gave up my ~$3K Macbook Pro to get a Windows machine.  
  
![mac vs win](/img/tflite/mac_vs_win.png){: .center-block :}  
  
By the end of this tutorial, I will provide zipped STM32 project files that you can download, extract, open using STM32CubeIDE, then build and deploy using just one button. Sounds simple enough? Let's get started.  
  
{: .box-note}  
**Note:** The TFLite Micro is still new (at the time of writing) and the library is changing almost daily basis. What I am about to show you might not work tomorrow. So, it will be a good idea to check [TFLite Micro GitHub repo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro) or [their website](https://www.tensorflow.org/lite/microcontrollers) for updated info.  
  
  {: .box-note}  
**Note:**  I will assume you are familiar with Python and used STM32Cube IDE before.
<br>  
