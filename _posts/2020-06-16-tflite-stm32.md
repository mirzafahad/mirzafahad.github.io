---
layout: post
title: How to run Neural Network model on STM32
subtitle: Part 1 - Training model and generating header file! 
gh-repo: mirzafahad/tflite_stm32
gh-badge: [star, fork, follow]
tags: [stm32, tensorflow, c, c++, python, neural netwrok, machine learning, microcontroller]
comments: true
---

# What is TinyML?
Machine Learning has been changing the world as we know it. With an abundance of data enabled by IoT devices, machine learning found its way even in niche applications. But running a machine learning algorithm requires a beefy workstation. There are machine learning frameworks that can be run on Single Board Computers (e.g. Raspberry Pi), but running on a microcontroller, pfff, out of the question. Until recently.

Tiny Machine Learning or [TinyML](https://www.tinyml.org/) is an emerging area of Machine Learning, where it tries to run various ML models on microcontrollers. [Pete Warden](https://twitter.com/petewarden), one of the key contributors of TinyML, was motivated to start this when he saw the OK Google team uses a 14KB Neural Network model on a DSP Microcontroller to listen for wake words "OK Google". In the 32bit microcontroller market, 14KB is pretty insignificant.

If you never heard of [TensorFlow](https://www.tensorflow.org/), it is an end-to-end open-source machine learning platform. There is a TF version specifically for Mobiles and Edge Devices, [TensorFlow Lite](https://www.tensorflow.org/lite). Now they also have an experimental port of this framework, [TensorFlow Lite for Microcontrollers](https://www.tensorflow.org/lite/microcontrollers). From their site:
>It doesn't require operating system support, any standard C or C++ libraries, or dynamic memory allocation. The core runtime fits in 16 KB on an Arm Cortex M3, and with enough operators to run a speech keyword detection model, takes up a total of 22 KB.

I will show an example of how to run a TFLite model in STM32F746G. I will be using [**32F746GDISCOVERY**](https://www.st.com/en/evaluation-tools/32f746gdiscovery.html) development board that has an LCD screen and you can buy a camera module as an addon. The example is based on the example that is available on the [TF GitHub](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world).

{: .box-note}  
**Note:** If the STM32 application becomes too much for you I would suggest you try one of their Arduino IDE examples. Those are pretty straight forward. I tried the SparkFun Edge example too. Not worth it, at all (at the time of writing).

# Why Rewrite the Example
  Here is an excerpt from the TF GitHub: 
>The default reference implementations in TensorFlow Lite Micro are written to be portable and easy to understand. The advantage of this approach is that we can automatically pick specialized implementations based on the microcontroller, without having to manually edit build files. It allows incremental optimizations from an always-working foundation, without cluttering the reference implementations with a lot of variants. 

>Using macros are hard to extend to multiple platforms. Using macros means that platform-specific code is scattered throughout files in a hard-to-find way, and can make following the control flow difficult since you need to understand the macro state to trace it. 

I get it. The team wants to support as many microcontrollers as they can. Any Embedded Engineers know, sometimes even two different series of microcontrollers from the same vendor aren't the same, not to mention, all the other vendors out there with their variants. That's why all the examples of the TFLite Micro are decoupled and abstracted so that you can easily port from one to another.

* This is the first reason I wanted to rewrite the example. I am mostly interested in STM32 microcontrollers. I am heavily invested into their [ecosystem](https://www.st.com/en/ecosystems/stm32cube.html). From IDE, Monitoring tool, CubeMx to their HAL libraries. I wanted to get away from all those abstractions and keep the example simple so that it is easier to follow.

The GitHub STM32 example uses [Mbed](https://os.mbed.com/). The compilation requires you to install Mbed CLI and Python 2.7. Also, if you are using Windows machine, good luck compiling it because Make fails because of the "path length" being too long.

* This is the 2nd reason. 
	* As I was already familiar with the STM32 ecosystem, I didn't want to get familiar with the Mbed ecosystem. 
	* The last time I used Python 2.x was back in 2016. I didn't want to mess up my near-perfect environment by installing another Python version. 
	* And, I am a Windows fan. At my current workplace, I gave up my ~$3K Macbook Pro to get a Windows machine.

![mac vs win](/img/tflite/mac_vs_win.png){: .center-block :}

By the end of this tutorial, I will provide zipped STM32 project files that you can download, extract, open using STM32CubeIDE, then build and deploy using just one button. Sounds simple enough? Let's get started.

{: .box-note}  
**Note:** The TFLite Micro is still new (at the time of writing) and the library is changing almost daily basis. What I am about to show you might not work tomorrow. So, it will be a good idea to check [TFLite Micro GitHub repo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro) or [their website](https://www.tensorflow.org/lite/microcontrollers) for updated info.

# Hello, World!
In this example, I will show you:
* How to train a model using TensorFlow 
* Convert the model to TFLite Micro with optimizations for hardware 
* Convert the model into C source file that can included in the microcontroller application 
* Run on-device inference

## Train a model
Well, what does that even mean? It means, we are going to show the model some input data and its corresponding output data and will ask it to figure out the relationship between input and output (known as *supervised learning*). Just like how you teach a toddler. For example, if you show a toddler enough pictures of dog, next time s/he saw a dog s/he will be able to guess its a dog. 

For our example though we want to build a sine wave function using Neural Network:
$$y = Sin(x)$$

We want to train a model that can take a value, '**x**', and predicts its sine, '**y**'. And to do that we will show the model thousands of samples (**x** and its corresponding **y**). The model will learn from it and will be able to predict **y** of new **x** values (this type of problem is called *regression*).

![model block diagram](/img/tflite/tflite_block.png){: .center-block :}

The model will take any value between 0 to 2pi and will predict the output between -1 to 1, without knowing what sine wave is. 

{: .box-note}  
**Note:** This example might sound ridiculous, but remember the goal of the tutorial is to show how to run a model on a microcontroller. This allows us to build a simple neural network which is also small enough to run on microcontrollers. Once you get familiar with the basic principles we will explore more challenging examples e.g. speech recognition, image processing, etc.

For training we will use [Google Colab](colab.research.google.com).  It is an online environment to run Python will all the required packages already installed. All you need is a Gmail account.

{: .box-note}  
**Note:** But if you already have everything installed on your workstation, feel free to use so.

The full code can be found here (will open on Google Colab). I will explain the code line by line here. 
* Head over to the [colab.research.google.com](colab.research.google.com).
